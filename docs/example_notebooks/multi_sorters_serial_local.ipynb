{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example runs single recording sorting using local computer\n",
    "# Created by James Jun on Feb 26, 2019\n",
    "\n",
    "# prerequisits\n",
    "# $ pip install ml_ms4alg\n",
    "# $ conda install -c conda-forge ipywidgets\n",
    "# $ jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "\n",
    "# please ignore the warning when running MountainSort4\n",
    "#   RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, datetime, json, numpy as np, pandas as pd, json\n",
    "import spikeforest_analysis as sa\n",
    "import spikeextractors as se\n",
    "import sfdata as sf\n",
    "from spikesorters import IronClust, MountainSort4, KiloSort, KiloSort2\n",
    "from spikeforest import spikewidgets as sw\n",
    "import ipywidgets as widgets\n",
    "from spikeforest_analysis.compare_sortings_with_truth import GenSortingComparisonTable\n",
    "from spikeforest_analysis.compute_units_info import ComputeUnitsInfo\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sorters\n",
    "f_force_run = True\n",
    "adjacency_radius = 100\n",
    "\n",
    "def irc(recpath, firings_out):\n",
    "    return IronClust.execute(\n",
    "            recording_dir=recpath,\n",
    "            firings_out=firings_out,\n",
    "            detect_sign=-1,\n",
    "            adjacency_radius=adjacency_radius,\n",
    "            prm_template_name='static',\n",
    "            _force_run=f_force_run)\n",
    "\n",
    "def irc_drift(recpath, firings_out):\n",
    "    return IronClust.execute(\n",
    "            recording_dir=recpath,\n",
    "            firings_out=firings_out,\n",
    "            detect_sign=-1,\n",
    "            adjacency_radius=adjacency_radius,\n",
    "            prm_template_name='drift',\n",
    "            _force_run=f_force_run)\n",
    "\n",
    "def ms4(recpath, firings_out):\n",
    "    return MountainSort4.execute(\n",
    "            recording_dir=recpath,\n",
    "            firings_out=firings_out,\n",
    "            detect_sign=-1,\n",
    "            adjacency_radius=adjacency_radius,\n",
    "            _force_run=f_force_run)\n",
    "\n",
    "def ksort(recpath, firings_out):\n",
    "    return KiloSort.execute(\n",
    "            recording_dir=recpath,\n",
    "            firings_out=firings_out,\n",
    "            detect_sign=-1,\n",
    "            adjacency_radius=adjacency_radius,\n",
    "            _force_run=f_force_run)\n",
    "\n",
    "def ksort2(recpath, firings_out):\n",
    "    return KiloSort2.execute(\n",
    "            recording_dir=recpath,\n",
    "            firings_out=firings_out,\n",
    "            detect_sign=-1,\n",
    "            adjacency_radius=adjacency_radius,\n",
    "            _force_run=f_force_run)\n",
    "\n",
    "#D_sorters = dict(KiloSort=ksort, IronClust_static=irc, MountainSort4=ms4, KiloSort2=ksort2, IronClust_drift=irc_drift)\n",
    "D_sorters = dict(KiloSort=ksort, IronClust_static=irc, MountainSort4=ms4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a data source and sorter\n",
    "# you may change the data source index and sorter index\n",
    "LS_sorter = list(D_sorters.keys())\n",
    "LS_sorter.insert(0,'all')\n",
    "\n",
    "widget1 = widgets.Dropdown(\n",
    "    options=LS_sorter, index=0, description='Spike sorters')\n",
    "display(widget1)\n",
    "\n",
    "LS_datasource = ['download', 'generate locally']\n",
    "widget2 = widgets.Dropdown(\n",
    "    options = LS_datasource, index=0, description='Data source')\n",
    "display(widget2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a parameters dictionary\n",
    "D_params = dict(\n",
    "    datasource = LS_datasource[widget2.index],\n",
    "    path_in = 'recordings/example1',\n",
    "    path_out = 'sortings/example1',\n",
    "    )\n",
    "\n",
    "S_sorter = LS_sorter[widget1.index]\n",
    "if S_sorter == 'all':\n",
    "    D_params['sorter'] = LS_sorter[1:]\n",
    "    \n",
    "else:\n",
    "    D_params['sorter'] = [S_sorter]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get recording\n",
    "path_in = D_params['path_in']\n",
    "# delete previous recording\n",
    "#  os.path.exists(recpath): shutil.rmtree(recpath)\n",
    "\n",
    "# delete previous output and make save\n",
    "path_in_true = os.path.join(path_in, 'firings_true.mda')\n",
    "path_in_json = os.path.join(path_in, 'units_info.json')\n",
    "\n",
    "if D_params['datasource'] == 'generate locally':\n",
    "    print(path_in_true)\n",
    "    if not os.path.exists(path_in_true):\n",
    "        # generate recording\n",
    "        rx, sx_true = se.example_datasets.toy_example1(\n",
    "            duration=600, num_channels=4, samplerate=30000, K=10)\n",
    "        print('Generated recording in ' + path_in)\n",
    "    else:\n",
    "        rx = se.MdaRecordingExtractor(path_in)\n",
    "        sx_true = se.MdaSortingExtractor(path_in_true)\n",
    "        print('Using cached recording in ' + path_in)\n",
    "else:\n",
    "    # download recording\n",
    "    #kpath = 'kbucket://15734439d8cf/groundtruth/magland_synth/datasets_noise10_K10_C4/001_synth'\n",
    "    #kpath = '/mnt/home/jjun/ceph/groundtruth/hybrid_drift/rec_32c_600s_11'\n",
    "    kpath = '/mnt/home/jjun/ceph/groundtruth/hybrid_drift/rec_64c_1200s_11'\n",
    "    rx = se.MdaRecordingExtractor(kpath, download=True)\n",
    "    sx_true = se.MdaSortingExtractor(kpath + '/firings_true.mda')   \n",
    "    \n",
    "if not os.path.exists(path_in): \n",
    "    os.makedirs(path_in)\n",
    "    se.MdaRecordingExtractor.writeRecording(recording=rx, save_path=path_in)\n",
    "    se.MdaSortingExtractor.writeSorting(\n",
    "        sorting=sx_true, save_path=path_in_true)\n",
    "        \n",
    "# summarize recording\n",
    "if not os.path.exists(path_in_json):\n",
    "    ComputeUnitsInfo.execute(\n",
    "        recording_dir = path_in,\n",
    "        firings = path_in_true,\n",
    "        json_out = path_in_json,\n",
    "        )\n",
    "with open(path_in_json) as f:\n",
    "    snr_json = json.load(f)\n",
    "    unit_snrs = [x['snr'] for x in snr_json]\n",
    "    unit_ids = [x['unit_id'] for x in snr_json]\n",
    "    sx_true.setUnitsProperty(property_name='snr', \n",
    "         values=unit_snrs, unit_ids=unit_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run spike sorting\n",
    "t1=datetime.datetime.now()\n",
    "\n",
    "path_in = D_params['path_in']\n",
    "path_out = D_params['path_out']\n",
    "LD_comparison = list()\n",
    "for S_sorter1 in D_params['sorter']:\n",
    "    # check if the sorting is done already\n",
    "    path_out1 = os.path.join(path_out, S_sorter1)\n",
    "    if not os.path.exists(path_out1): \n",
    "        os.makedirs(path_out1)  \n",
    "    path_out_firings1 = os.path.join(path_out1, 'firings_out.mda')\n",
    "    if not os.path.exists(path_out_firings1):\n",
    "        print('Running '+ S_sorter1 + ' in notebook.')\n",
    "        D_sorters[S_sorter1](path_in, path_out_firings1)\n",
    "    else:\n",
    "        print('Loaded '+ S_sorter1 + ' from ' + path_out_firings1)\n",
    "    sx1 = se.MdaSortingExtractor(path_out_firings1)\n",
    "    \n",
    "    # validation           \n",
    "    path_out_json1 = os.path.join(path_out1, 'sorting_comparison.json')\n",
    "    if not os.path.exists(path_out_json1):\n",
    "        print('Computing comparison...')\n",
    "        GenSortingComparisonTable.execute(\n",
    "            firings = path_out_firings1,\n",
    "            units_true = None,\n",
    "            firings_true = os.path.join(path_in, 'firings_true.mda'),\n",
    "            json_out = path_out_json1,\n",
    "            html_out = os.path.join(path_out1, 'sorting_comparison.html'),\n",
    "            )\n",
    "    else:\n",
    "        print('Loading comparison...')\n",
    "        \n",
    "    df1 = pd.read_json(path_or_buf=path_out_json1)    \n",
    "    L_unit_id = [int(x) for x in df1.transpose()['unit_id'].to_list()]\n",
    "    L_accuracy = df1.transpose()['accuracy'].to_list()\n",
    "    L_snr = sx_true.getUnitsProperty(unit_ids=L_unit_id, property_name='snr')\n",
    "    L_recall = [1-x for x in df1.transpose()['f_n'].to_list()]\n",
    "    L_precision = [1-x for x in df1.transpose()['f_p'].to_list()]\n",
    "    D_comparison1 = dict(\n",
    "        L_snr = L_snr, S_sorter=S_sorter1, \n",
    "        L_accuracy = L_accuracy, L_recall = L_recall, L_precision = L_precision)\n",
    "    LD_comparison.append(D_comparison1)\n",
    "    \n",
    "dt = datetime.datetime.now() - t1\n",
    "print('took {:0.3f}s'.format(dt.total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot SNR vs accuracy for the first sorting output\n",
    "accuracy_thresh, snr_thresh = .8, 8\n",
    "\n",
    "#LD_comparison1 = [LD_comparison[i] for i in [3,1,4,0,2]]\n",
    "LD_comparison1 = LD_comparison\n",
    "for D_comparison1 in LD_comparison1:\n",
    "    fig=plt.figure(figsize=(12,3))\n",
    "    L_accuracy1 = D_comparison1['L_accuracy']\n",
    "    L_recall1 = D_comparison1['L_recall']\n",
    "    L_precision1 = D_comparison1['L_precision']\n",
    "    L_snr1 = D_comparison1['L_snr']\n",
    "    S_sorter1 = D_comparison1['S_sorter']\n",
    "    \n",
    "    print(S_sorter1)\n",
    "    ax=fig.add_subplot(1,3,1)\n",
    "    ax.plot(L_snr, L_accuracy1, '.')\n",
    "    plt.xlabel('SNR')\n",
    "    plt.ylabel('accuracy')    \n",
    "    plt.ylim(0,1)\n",
    "    nUnits_above = np.sum(np.array(L_accuracy1) >= accuracy_thresh)\n",
    "    plt.title('{} units > {} accuracy'.format(nUnits_above, accuracy_thresh))  \n",
    "    \n",
    "    ax=fig.add_subplot(1,3,2)\n",
    "    ax.plot(L_snr, L_recall1, '.')\n",
    "    plt.xlabel('SNR')\n",
    "    plt.ylabel('recall')    \n",
    "    plt.ylim(0,1)\n",
    "    nUnits_above = np.sum(np.array(L_recall1) >= accuracy_thresh)\n",
    "    plt.title('{} units > {} recall'.format(nUnits_above, accuracy_thresh))  \n",
    "    \n",
    "    ax=fig.add_subplot(1,3,3)\n",
    "    ax.plot(L_snr, L_precision1, '.')\n",
    "    plt.xlabel('SNR')\n",
    "    plt.ylabel('precision')    \n",
    "    plt.ylim(0,1)\n",
    "    nUnits_above = np.sum(np.array(L_precision1) >= accuracy_thresh)\n",
    "    plt.title('{} units > {} precision'.format(nUnits_above, accuracy_thresh))  \n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
