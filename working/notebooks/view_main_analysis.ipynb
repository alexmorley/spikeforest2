{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View main analysis\n",
    "\n",
    "This notebook provides a view into a snapshot of the SpikeForest analysis. A snapshot URL may be obtained from the \"Archive\" section of the website or it may be created offline using the spikeforest Python package.\n",
    "\n",
    "Because this notebook is checked into the git repo, it is a good idea to make a working copy before running or modifying it. If you do modify and push back to the repo, please clear the outputs first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from mountaintools import client as mt\n",
    "from spikeforest import SFMdaRecordingExtractor, SFMdaSortingExtractor\n",
    "# from spikeforest import MainAnalysisView\n",
    "import spikeforestwidgets as SFW\n",
    "import vdomr as vd\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the analysis snapshot object\n",
    "# You can obtain a snapshot URL from the \"Archive\" section of the website\n",
    "# or you can use a path to a local file\n",
    "snapshot_path = 'sha1://d0eb11774305a926e75ad232e4a6b4a54ffed4b2/analysis.json'\n",
    "\n",
    "# Configure mountaintools to download from the public spikeforest kachery\n",
    "mt.configDownloadFrom('spikeforest.public')\n",
    "A = mt.loadObject(path=snapshot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainAnalysisView():\n",
    "    def __init__(self, obj: dict):\n",
    "        self._obj = obj\n",
    "        self._metric = 'accuracy'  # accuracy, precision, recall\n",
    "        self._mode = 'average'  # average or count\n",
    "        self._snr_threshold = 8\n",
    "        self._metric_threshold = 0.8\n",
    "\n",
    "    def mainTable(self):        \n",
    "        A = self._obj\n",
    "        snr_threshold = 8\n",
    "        sorters = A['Sorters']\n",
    "        table_rows = []\n",
    "        for sset in A['StudySets']:\n",
    "            # display(vd.h5(sset['name']))\n",
    "            for study in sset['studies']:\n",
    "                sar = self._find_study_analysis_result(study['name'])\n",
    "                assert sar\n",
    "                row = dict(\n",
    "                    study=study['name']\n",
    "                )\n",
    "                for sr in sar['sortingResults']:\n",
    "                    sorter_name = sr['sorterName']\n",
    "                    SRs = self._find_sorting_results(study['name'], sorter_name)\n",
    "                    if len(SRs) > 0:\n",
    "                        if self._mode == 'average':\n",
    "                            val = self._compute_average(sar, sr)\n",
    "                        elif self._mode == 'count':\n",
    "                            val = self._compute_count(sar, sr)\n",
    "                        else:\n",
    "                            val = 0\n",
    "                        num_missing = self._count_missing(sr)\n",
    "                        if num_missing > 0:\n",
    "                            val = '{}*'.format(round(val, 2))\n",
    "                        else:\n",
    "                            val = '{}'.format(round(val, 2))\n",
    "                    else:\n",
    "                        val = ''\n",
    "                    row[sorter_name] = val\n",
    "                table_rows.append(row)\n",
    "        df = pd.DataFrame(table_rows)\n",
    "        df = df[['study'] + [sorter['name'] for sorter in sorters]]\n",
    "        return df\n",
    "    \n",
    "    def setMetric(self, metric: str):\n",
    "        self._metric = metric\n",
    "        \n",
    "    def setMode(self, mode: str):\n",
    "        self._mode = mode\n",
    "    \n",
    "    def _compute_average(self, sar: dict, sorting_result:dict):\n",
    "        snr_threshold = self._snr_threshold\n",
    "        snrs = sar['trueSnrs']\n",
    "        if self._metric == 'accuracy':\n",
    "            x = sorting_result['accuracies']\n",
    "        elif self._metric == 'precision':\n",
    "            x = sorting_result['precisions']\n",
    "        elif self._metric == 'recall':\n",
    "            x = sorting_result['recalls']\n",
    "        else:\n",
    "            raise Exception('Invalid metric: {}'.format(self._metric))\n",
    "        x_to_use = [x[i] for i in range(len(x)) if snrs[i] is not None and snrs[i] >= snr_threshold]\n",
    "        x_to_use = [x for x in x_to_use if x is not None]\n",
    "        if x_to_use:\n",
    "            return np.mean(x_to_use)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def _compute_count(self, sar: dict, sorting_result:dict):\n",
    "        metric_threshold = self._metric_threshold\n",
    "        if self._metric == 'accuracy':\n",
    "            x = sorting_result['accuracies']\n",
    "        elif self._metric == 'precision':\n",
    "            x = sorting_result['precisions']\n",
    "        elif self._metric == 'recall':\n",
    "            x = sorting_result['recall']\n",
    "        else:\n",
    "            raise Exception('Invalid metric: {}'.format(self._metric))\n",
    "        x_to_use = [x[i] for i in range(len(x)) if x[i] is not None and x[i] >= metric_threshold]\n",
    "        return len(x_to_use)\n",
    "    \n",
    "    def _find_sorting_results(self, study_name: str, sorter_name: str):\n",
    "        return [SR for SR in self._obj['SortingResults'] if (SR['studyName'] == study_name) and (SR['sorterName'] == sorter_name)]\n",
    "\n",
    "    def _find_study_analysis_result(self, study_name: str):\n",
    "        A = self._obj\n",
    "        for x in A['StudyAnalysisResults']:\n",
    "            if x['studyName'] == study_name:\n",
    "                return x\n",
    "    def _count_missing(self, sorting_result: dict):\n",
    "        return len([x for x in sorting_result['accuracies'] if x is None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = MainAnalysisView(A)\n",
    "V.setMode('average')\n",
    "V.setMetric('accuracy')\n",
    "display(V.mainTable())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# James: here is how to superimpose an updated analysis on top of an existing one:\n",
    "\n",
    "from_website = mt.loadObject(path='sha1://d0eb11774305a926e75ad232e4a6b4a54ffed4b2/analysis.json')\n",
    "update = mt.loadObject(path='key://pairio/spikeforest/test1.json')\n",
    "sorter_names_in_update = [s['name'] for s in update['Sorters']]\n",
    "for sr in from_website['SortingResults']:\n",
    "    if sr['sorterName'] not in sorter_names_in_update:\n",
    "        update['SortingResults'].append(sr)\n",
    "for sar in update['StudyAnalysisResults']:\n",
    "    sarW = find_study_analysis_result(from_website, sar['studyName'])\n",
    "    for sr in sarW['sortingResults']:\n",
    "        if sr['sorterName'] not in sorter_names_in_update:\n",
    "            sar['sortingResults'].append(sr)\n",
    "for sorter in from_website['Sorters']:\n",
    "    if sorter['name'] not in sorter_names_in_update:\n",
    "        update['Sorters'].append(sorter)\n",
    "        \n",
    "A=update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD INFO\n",
    "\n",
    "# An example command for James:\n",
    "# > ./assemble_website_data.py --output_ids hybrid_janelia_irc,paired_kampff_irc --dest_key_path output.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
