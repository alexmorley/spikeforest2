{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble website data\n",
    "\n",
    "This notebook saves collections in .json files in the website_data/ directory\n",
    "\n",
    "StudySets.json\n",
    "Studies.json\n",
    "Recordings.json\n",
    "TrueUnits.json\n",
    "UnitResults.json\n",
    "Sorters.json\n",
    "\n",
    "## Schema\n",
    "\n",
    "StudySet\n",
    "* name (str)\n",
    "* [type (str) -- synthetic, real, hybrid, etc.]\n",
    "* [description (str)]\n",
    "    \n",
    "Study\n",
    "* name (str)\n",
    "* studySet (str)\n",
    "* description (str)\n",
    "* sorterNames (array of str)\n",
    "\n",
    "Note: study name is unique, even across study sets\n",
    "    \n",
    "Recording\n",
    "* name (str)\n",
    "* study (str)\n",
    "* directory (str) -- i.e., kbucket address\n",
    "* description (str)\n",
    "* sampleRateHz (float)\n",
    "* numChannels (int)\n",
    "* durationSec (float)\n",
    "* numTrueUnits (int)\n",
    "* [fileSizeBytes (int)]\n",
    "* spikeSign (int) [Hard-coded for now. In future, grab from params.json]\n",
    "\n",
    "TrueUnit\n",
    "* unitId (int)\n",
    "* recording (str)\n",
    "* study (str)\n",
    "* meanFiringRateHz (float)\n",
    "* numEvents (int)\n",
    "* peakChannel (int)\n",
    "* snr (float)\n",
    "\n",
    "SortingResult\n",
    "* recording (str)\n",
    "* study (str)\n",
    "* sorter (str)\n",
    "* cpuTimeSec (float)\n",
    "* [runtime_info (object): timestamps, wall time, CPU time, RAM usage, error status]\n",
    "* [firingsOutputUrl (str)] TODO: jfm (two weeks)\n",
    "\n",
    "UnitResult\n",
    "* unitId (int)\n",
    "* recording (str)\n",
    "* study (str)\n",
    "* sorter (str)\n",
    "* numMatches (int)\n",
    "* numFalsePositives (int)\n",
    "* numFalseNegatives (int)\n",
    "* checkAccuracy (float)\n",
    "* checkRecall (float)\n",
    "* checkPrecision (float)\n",
    "* bestSortedUnitId (int)\n",
    "* spikeSprayUrl (str) TODO: jfm to make this (next week)\n",
    "\n",
    "Sorter\n",
    "* name (str)\n",
    "* algorithm (str)\n",
    "* [algorithmVersion (str)] - future\n",
    "* processorName (str)\n",
    "* processorVersion (str)\n",
    "* sortingParameters (object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from mountaintools import client as mt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved share_id 69432e9201d0 from alias spikeforest.spikeforest2\n",
      "MOUNTAIN CONFIG: remote database spikeforest (readonly); remote kb-share 69432e9201d0 (readonly)\n"
     ]
    }
   ],
   "source": [
    "mt.configRemoteReadonly(collection='spikeforest', share_id='spikeforest.spikeforest2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ids=['visapy_mea', 'magland_synth', 'mearec_neuronexus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_objects=[\n",
    "    mt.loadObject(\n",
    "        key=dict(\n",
    "            name='spikeforest_results'\n",
    "        ),\n",
    "        subkey=output_id\n",
    "    )\n",
    "    for output_id in output_ids\n",
    "]\n",
    "studies=[study for X in result_objects for study in X['studies']]\n",
    "recordings=[recording for X in result_objects for recording in X['recordings']]\n",
    "sorting_results=[sorting_result for X in result_objects for sorting_result in X['sorting_results']]\n",
    "\n",
    "if not os.path.exists('website_data'):\n",
    "    os.mkdir('website_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'visapy_mea'}, {'name': 'magland_synth'}, {'name': 'mearec_neuronexus'}]\n"
     ]
    }
   ],
   "source": [
    "### STUDY SETS\n",
    "\n",
    "study_sets_by_name=dict()\n",
    "for study in studies:\n",
    "    study_sets_by_name[study['study_set']]=dict(name=study['study_set'])\n",
    "\n",
    "StudySets=[]\n",
    "for study_set in study_sets_by_name.values():\n",
    "    StudySets.append(dict(\n",
    "        name=study_set['name']\n",
    "    ))\n",
    "\n",
    "mt.saveObject(object=StudySets, dest_path=os.path.abspath(os.path.join('website_data', 'StudySets.json')))\n",
    "print(StudySets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num recordings: 146\n",
      "Num true units: 2696\n",
      "studies for recordings: {'mearec_neuronexus_noise10_K40_C32', 'mearec_neuronexus_noise20_K20_C32', 'magland_synth_noise20_K20_C8', 'mearec_neuronexus_noise20_K40_C32', 'magland_synth_noise10_K20_C8', 'magland_synth_noise20_K10_C4', 'magland_synth_noise10_K10_C4', 'magland_synth_noise10_K10_C8', 'mearec_neuronexus_noise20_K10_C32', 'magland_synth_noise10_K20_C4', 'magland_synth_noise20_K10_C8', 'mearec_neuronexus_noise10_K10_C32', 'mearec_neuronexus_noise10_K20_C32', 'magland_synth_noise20_K20_C4', 'visapy_mea'}\n"
     ]
    }
   ],
   "source": [
    "### RECORDINGS and TRUE UNITS\n",
    "\n",
    "Recordings=[]\n",
    "TrueUnits=[]\n",
    "for recording in recordings:\n",
    "    true_units_info=mt.loadObject(path=recording['summary']['true_units_info'])\n",
    "    for unit_info in true_units_info:\n",
    "        TrueUnits.append(dict(\n",
    "            unitId=unit_info['unit_id'],\n",
    "            recording=recording['name'],\n",
    "            study=recording['study'],\n",
    "            meanFiringRateHz=unit_info['firing_rate'],\n",
    "            numEvents=unit_info['num_events'],\n",
    "            peakChannel=unit_info['peak_channel'],\n",
    "            snr=unit_info['snr'],\n",
    "        ))\n",
    "    Recordings.append(dict(\n",
    "        name=recording['name'],\n",
    "        study=recording['study'],\n",
    "        directory=recording['directory'],\n",
    "        description=recording['description'],\n",
    "        sampleRateHz=recording['summary']['computed_info']['samplerate'],\n",
    "        numChannels=recording['summary']['computed_info']['num_channels'],\n",
    "        durationSec=recording['summary']['computed_info']['duration_sec'],\n",
    "        numTrueUnits=len(true_units_info),\n",
    "        spikeSign=-1\n",
    "    ))\n",
    "\n",
    "mt.saveObject(object=Recordings, dest_path=os.path.abspath(os.path.join('website_data', 'Recordings.json')))\n",
    "mt.saveObject(object=TrueUnits, dest_path=os.path.abspath(os.path.join('website_data', 'TrueUnits.json')))\n",
    "print('Num recordings:',len(Recordings))\n",
    "print('Num true units:',len(TrueUnits))\n",
    "print('studies for recordings:',set([recording['study'] for recording in Recordings]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115.23310160636902"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorting_results[0]['execution_stats']['elapsed_sec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num unit results: 10784\n"
     ]
    }
   ],
   "source": [
    "### UNIT RESULTS and SORTING RESULTS\n",
    "\n",
    "UnitResults=[]\n",
    "SortingResults=[]\n",
    "sorter_names_by_study=dict()\n",
    "for sr in sorting_results:\n",
    "    SortingResults.append(dict(\n",
    "        recording=sr['recording']['name'],\n",
    "        study=sr['recording']['study'],\n",
    "        sorter=sr['sorter']['name'],\n",
    "        cpuTimeSec=sr['execution_stats'].get('elapsed_sec',None)\n",
    "    ))\n",
    "    comparison_with_truth=mt.loadObject(path=sr['comparison_with_truth']['json'])\n",
    "    for unit_result in comparison_with_truth.values():\n",
    "        study_name=sr['recording']['study']\n",
    "        sorter_name=sr['sorter']['name']\n",
    "        if study_name not in sorter_names_by_study:\n",
    "            sorter_names_by_study[study_name]=set()\n",
    "        sorter_names_by_study[study_name].add(sorter_name)\n",
    "        n_match=unit_result['num_matches']\n",
    "        n_fp=unit_result['num_false_positives']\n",
    "        n_fn=unit_result['num_false_negatives']\n",
    "        UnitResults.append(dict(\n",
    "            unitId=unit_result['unit_id'],\n",
    "            recording=sr['recording']['name'],\n",
    "            study=study_name,\n",
    "            sorter=sorter_name,\n",
    "            numMatches=n_match,\n",
    "            numFalsePositives=n_fp,\n",
    "            numFalseNegatives=n_fn,\n",
    "            checkAccuracy=n_match/(n_match+n_fp+n_fn),\n",
    "            checkPrecision=n_match/(n_match+n_fn),\n",
    "            checkRecall=n_match/(n_match+n_fp),\n",
    "            bestSortedUnitId=unit_result['best_unit']\n",
    "        ))\n",
    "for study in sorter_names_by_study.keys():\n",
    "    sorter_names_by_study[study]=list(sorter_names_by_study[study])\n",
    "    sorter_names_by_study[study].sort()\n",
    "mt.saveObject(object=UnitResults, dest_path=os.path.abspath(os.path.join('website_data', 'UnitResults.json')))  \n",
    "mt.saveObject(object=SortingResults, dest_path=os.path.abspath(os.path.join('website_data', 'SortingResults.json')))  \n",
    "print('Num unit results:',len(UnitResults))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MountainSort4-thr3', 'SpykingCircus', 'Yass', 'IronClust-static']\n"
     ]
    }
   ],
   "source": [
    "### SORTERS\n",
    "\n",
    "sorters_by_name=dict()\n",
    "for sr in sorting_results:\n",
    "    sorters_by_name[sr['sorter']['name']]=sr['sorter']\n",
    "    \n",
    "Sorters=[]\n",
    "for name,sorter in sorters_by_name.items():\n",
    "    Sorters.append(dict(\n",
    "        name=sorter['name'],\n",
    "        algorithm=sorter['processor_name'], # right now the algorithm is the same as the processor name\n",
    "        processorName=sorter['processor_name'],\n",
    "        processorVersion='0', # jfm needs to provide this\n",
    "        sorting_parameters=sorter['params'] # Liz, even though most sorters have similar parameter names, it won't always be like that. The params is an arbitrary json object.\n",
    "    ))\n",
    "\n",
    "mt.saveObject(object=Sorters, dest_path=os.path.abspath(os.path.join('website_data', 'Sorters.json')))\n",
    "print([S['name'] for S in Sorters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['visapy_mea', 'magland_synth_noise10_K10_C4', 'magland_synth_noise10_K10_C8', 'magland_synth_noise10_K20_C4', 'magland_synth_noise10_K20_C8', 'magland_synth_noise20_K10_C4', 'magland_synth_noise20_K10_C8', 'magland_synth_noise20_K20_C4', 'magland_synth_noise20_K20_C8', 'mearec_neuronexus_noise10_K10_C32', 'mearec_neuronexus_noise10_K20_C32', 'mearec_neuronexus_noise10_K40_C32', 'mearec_neuronexus_noise20_K10_C32', 'mearec_neuronexus_noise20_K20_C32', 'mearec_neuronexus_noise20_K40_C32']\n"
     ]
    }
   ],
   "source": [
    "### STUDIES\n",
    "\n",
    "Studies=[]\n",
    "for study in studies:\n",
    "    Studies.append(dict(\n",
    "        name=study['name'],\n",
    "        studySet=study['study_set'],\n",
    "        description=study['description'],\n",
    "        sorterNames=sorter_names_by_study[study['name']]\n",
    "        # the following can be obtained from the other collections\n",
    "        # numRecordings, sorters, etc...\n",
    "    ))\n",
    "\n",
    "mt.saveObject(object=Studies, dest_path=os.path.abspath(os.path.join('website_data', 'Studies.json')))\n",
    "print([S['name'] for S in Studies])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
